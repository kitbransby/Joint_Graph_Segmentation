{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ffe97a6-4677-464d-a8d4-1f89d7232a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Code adapted from https://github.com/ngaggion/HybridGNet\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b12f9e-c4b0-4a0c-9453-f74db922e367",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194a5e9a-1afc-4a5f-9686-74a4863507e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "325890ef-4d82-48b3-a62e-2835c553fb15",
   "metadata": {},
   "source": [
    "## Train-Val-Test splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090aa026-fa2d-4281-a7cf-ef932f807b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train_list.txt') as file:\n",
    "    train_list = [line.rstrip() for line in file]\n",
    "    \n",
    "with open('val_list.txt') as file:\n",
    "    val_list = [line.rstrip() for line in file]\n",
    "    \n",
    "with open('test_list.txt') as file:\n",
    "    test_list = [line.rstrip() for line in file]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098a3ce5-2489-4035-9eea-781b161d470d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_list), len(val_list), len(test_list), len(train_list)+len(val_list)+len(test_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "796dce81-1e88-4535-9117-8d94cf9ddbe1",
   "metadata": {},
   "source": [
    "## Process Landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c341d4-f818-45f4-b510-4d28fdcac22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "RL_files = [f for f in glob.glob('../All_Landmarks/RL/*.npy') if len(f) > 60]\n",
    "LL_files = [f for f in glob.glob('../All_Landmarks/LL/*.npy') if len(f) > 60]\n",
    "H_files = [f for f in glob.glob('../All_Landmarks/H/*.npy') if len(f) > 60]\n",
    "len(RL_files), len(LL_files), len(H_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8d9d0d-5e04-4b77-a221-d2016a683da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for RL_file, LL_file, H_file in zip(RL_files, LL_files, H_files):\n",
    "    RL = np.load(RL_file)\n",
    "    LL = np.load(LL_file)\n",
    "    H = np.load(H_file)\n",
    "    L = np.concatenate([RL, LL, H], axis=0)\n",
    "    np.save('Landmarks/' + LL_file.split('/')[-1], L)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30af6246-f757-4f3a-9f6f-bfaf190f99ac",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Preprocess Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee515ec-e46f-4c4b-8099-b66667523eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files = glob.glob('Images/*.png')\n",
    "len(all_files), all_files[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5cfd3f-e6af-4422-92f6-267b8a363da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n",
    "\n",
    "for file in all_files:\n",
    "    print('\\r',i,'of', len(all_files),end='')\n",
    "\n",
    "    # preprocess images\n",
    "\n",
    "    img = cv2.imread(file, 0)\n",
    "\n",
    "    gray = 255*(img > 1) # To invert the text to white\n",
    "    coords = cv2.findNonZero(gray) # Find all non-zero points (text)\n",
    "\n",
    "    x, y, w, h = cv2.boundingRect(coords) # Find minimum spanning bounding box\n",
    "    cropimg = img[y:y+h, x:x+w] # Crop the image - note we do this on the original image\n",
    "\n",
    "    shape = cropimg.shape\n",
    "\n",
    "    if shape[0] < shape[1]:\n",
    "        pad = (shape[1] - shape[0])    \n",
    "\n",
    "        if pad % 2 == 1:\n",
    "            pad = pad // 2\n",
    "            pad_y = [pad, pad+1]\n",
    "        else:\n",
    "            pad = pad // 2\n",
    "            pad_y = [pad, pad]\n",
    "\n",
    "        pad_x = [0, 0]\n",
    "    elif shape[1] < shape[0]:\n",
    "        pad = (shape[0] - shape[1]) \n",
    "\n",
    "        if pad % 2 == 1:\n",
    "            pad = pad // 2\n",
    "            pad_x = [pad, pad+1]\n",
    "        else:\n",
    "            pad = pad // 2\n",
    "            pad_x = [pad, pad]\n",
    "\n",
    "        pad_y = [0, 0]\n",
    "\n",
    "    img = np.pad(cropimg, pad_width = [pad_y, pad_x])    \n",
    "\n",
    "    if img.shape[0] != img.shape[1]:\n",
    "        print('Error padding image')\n",
    "        break\n",
    "\n",
    "    img_ = cv2.resize(img, [1024, 1024])\n",
    "\n",
    "    if file.split('/')[-1].split('.')[0] in train_list:\n",
    "        cv2.imwrite('Train/'+file, img_)\n",
    "        \n",
    "    elif file.split('/')[-1].split('.')[0] in val_list:\n",
    "        cv2.imwrite('Val/'+file, img_)\n",
    "        \n",
    "    elif file.split('/')[-1].split('.')[0] in test_list:\n",
    "        cv2.imwrite('Test/'+file, img_)\n",
    "    else:\n",
    "        print('File not in list')\n",
    "        \n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cdcbf83-618d-435f-a692-4dba5fc4e867",
   "metadata": {},
   "source": [
    "## Create and Process Masks/Landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea0d84a-1353-4ffe-85b1-d0606422031f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b793a99-fb37-4e55-afc4-556068e6e600",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.fun import drawBinary, reverseVector\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ecfe7d-697f-410c-b1a9-0557bc2b2c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "blank = np.zeros([1024, 1024])\n",
    "\n",
    "for list_str, list_ in [['Train/', train_list], ['Val/', val_list], ['Test/', test_list]]:\n",
    "    for example in list_:\n",
    "        landmarks = np.load('Landmarks/'+example+'.npy')\n",
    "        \n",
    "        p1, p2, h, c1, c2 = reverseVector(landmarks.reshape(-1))\n",
    "        lungs = drawBinary(np.zeros([1024,1024]), p1)\n",
    "        lungs = drawBinary(lungs, p2)\n",
    "        heart = drawBinary(np.zeros([1024,1024]), h)\n",
    "\n",
    "        mask = np.zeros([1024, 1024])\n",
    "        mask[heart == 255] = 2\n",
    "        mask[lungs == 255] = 1\n",
    "        \n",
    "        assert np.all(np.unique(mask) == [0., 1., 2.])\n",
    "\n",
    "        #np.save(list_str+'Masks/'+example+'.npy', LUNG_mask)\n",
    "        #np.save(list_str+'Landmarks/'+example+'.npy', landmarks)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e17009e-27e3-4c9c-9266-2a9cc4e28ce2",
   "metadata": {},
   "source": [
    "## Create SDF ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a54ac9-49e2-43a4-8cea-6b3489823058",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.SDF import sdf\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4590465e-0a26-4775-b360-3346a09c166a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_paths = glob.glob('*/Masks/*.npy')\n",
    "len(mask_paths), mask_paths[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a32374-57fd-42d1-9894-d85e802ec409",
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in tqdm(mask_paths):\n",
    "    mask = np.load(path)\n",
    "    lung_sdf = sdf(mask, organ=1)\n",
    "    heart_sdf = sdf(mask, organ=2)\n",
    "    lung_heart_sdf = np.stack([lung_sdf, heart_sdf], -1)\n",
    "    np.save(path.replace('Masks', 'SDF'), lung_sdf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_1.11",
   "language": "python",
   "name": "torch_1.11"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
