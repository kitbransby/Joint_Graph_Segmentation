{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d042d203-9c47-453b-b6c2-85ae1fefe7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Code adapted from https://github.com/ngaggion/HybridGNet\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ed5444-1041-4186-9f16-31f453fcfed9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af702e31-9ac9-424c-8769-8f209dba81dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55390967-692a-4df0-9c9e-0c4b8566ab5a",
   "metadata": {},
   "source": [
    "## Train-Val-Test splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303aa55f-58be-4a63-8241-074fdd14573f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train_list.txt') as file:\n",
    "    train_list = [line.rstrip() for line in file]\n",
    "    \n",
    "with open('val_list.txt') as file:\n",
    "    val_list = [line.rstrip() for line in file]\n",
    "    \n",
    "with open('test_list.txt') as file:\n",
    "    test_list = [line.rstrip() for line in file]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d41a510-343a-4a17-8ea5-2d9a4b95ac83",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Process Landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739c4781-d1f5-4d31-8f7a-7e6a80b1c677",
   "metadata": {},
   "outputs": [],
   "source": [
    "RL_files = glob.glob('../All_Landmarks/RL/MCU*.npy')\n",
    "LL_files = glob.glob('../All_Landmarks/LL/MCU*.npy')\n",
    "len(RL_files), len(LL_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ab25b9-d6f3-4d85-81f6-e2a0a03e5900",
   "metadata": {},
   "outputs": [],
   "source": [
    "for RL_file, LL_file in zip(RL_files, LL_files):\n",
    "    RL = np.load(RL_file)\n",
    "    LL = np.load(LL_file)\n",
    "    L = np.concatenate([RL, LL], axis=0)\n",
    "    np.save('Landmarks/' + LL_file.split('/')[-1], L)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62fec968-1521-4456-a7b2-e9786af3ed26",
   "metadata": {},
   "source": [
    "## Preprocess Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e75fbc9-4398-4867-8188-fc395bc026f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files = glob.glob('Images/*.png')\n",
    "len(all_files), all_files[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0628156c-5356-43fb-a0b4-572e8fc6cbbf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "i = 1\n",
    "\n",
    "for file in all_files:\n",
    "    print('\\r',i,'of', len(all_files),end='')\n",
    "\n",
    "    img = cv2.imread(file, 0)\n",
    "\n",
    "    gray = 255*(img > 1) # To invert the text to white\n",
    "    coords = cv2.findNonZero(gray) # Find all non-zero points (text)\n",
    "\n",
    "    x, y, w, h = cv2.boundingRect(coords) # Find minimum spanning bounding box\n",
    "    cropimg = img[y:y+h, x:x+w] # Crop the image - note we do this on the original image\n",
    "\n",
    "    shape = cropimg.shape\n",
    "\n",
    "    if shape[0] < shape[1]:\n",
    "        pad = (shape[1] - shape[0])    \n",
    "        \n",
    "        if pad % 2 == 1:\n",
    "            pad = pad // 2\n",
    "            pad_y = [pad, pad+1]\n",
    "        else:\n",
    "            pad = pad // 2\n",
    "            pad_y = [pad, pad]\n",
    "            \n",
    "        pad_x = [0, 0]\n",
    "    elif shape[1] < shape[0]:\n",
    "        pad = (shape[0] - shape[1]) \n",
    "        \n",
    "        if pad % 2 == 1:\n",
    "            pad = pad // 2\n",
    "            pad_x = [pad, pad+1]\n",
    "        else:\n",
    "            pad = pad // 2\n",
    "            pad_x = [pad, pad]\n",
    "            \n",
    "        pad_y = [0, 0]\n",
    "\n",
    "    img = np.pad(cropimg, pad_width = [pad_y, pad_x])    \n",
    "\n",
    "    if img.shape[0] != img.shape[1]:\n",
    "        print('Error padding image')\n",
    "        break\n",
    "\n",
    "    img_ = cv2.resize(img, [1024, 1024])\n",
    "    \n",
    "    if file.split('/')[-1].split('.')[0] in train_list:\n",
    "        cv2.imwrite('Train/'+file, img_)\n",
    "        #pass\n",
    "    elif file.split('/')[-1].split('.')[0] in val_list:\n",
    "        cv2.imwrite('Val/'+file, img_)\n",
    "        #pass\n",
    "    elif file.split('/')[-1].split('.')[0] in test_list:\n",
    "        cv2.imwrite('Test/'+file, img_)\n",
    "        #pass\n",
    "    else:\n",
    "        print('File not in list')\n",
    "\n",
    "    i = i+1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d275f8b4-153f-43ec-9fd4-5a3893aac65e",
   "metadata": {},
   "source": [
    "## Create and Process Masks/Landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980c72a2-461d-4c3f-b81e-2e6197080bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe38f59-098a-4242-85cb-90fcba90e2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.fun import drawBinary, reverseVector\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7151797-e686-46d0-9951-14557adef0a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "blank = np.zeros([1024, 1024])\n",
    "\n",
    "for list_str, list_ in [['Train/', train_list], ['Val/', val_list], ['Test/', test_list]]:\n",
    "    for example in list_:\n",
    "        landmarks = np.load('Landmarks/'+example+'.npy')\n",
    "        p1, p2, _, _, _ = reverseVector(landmarks.reshape(-1))\n",
    "        RLUNG = drawBinary(blank.copy(), p1)\n",
    "        LLUNG = drawBinary(blank.copy(), p2)\n",
    "        \n",
    "        LUNG_mask = (RLUNG + LLUNG) / 255\n",
    "        \n",
    "        assert np.all(np.unique(LUNG_mask) == [0., 1.])\n",
    "\n",
    "        np.save(list_str+'Masks/'+example+'.npy', LUNG_mask)\n",
    "        np.save(list_str+'Landmarks/'+example+'.npy', landmarks)\n",
    "        \n",
    "        #plt.figure(figsize=(10,10))\n",
    "        #plt.scatter(*landmarks.T)\n",
    "        #plt.imshow(LUNG_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28ca770-6b5f-4cd0-92ae-39a206001bd1",
   "metadata": {},
   "source": [
    "## Create SDF ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754dafc1-39b9-4e9c-b72a-eaaca34e640c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.SDF import sdf\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51df69d7-3472-43a5-9bb5-c957e176ab8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_paths = glob.glob('*/Masks/*.npy')\n",
    "len(mask_paths), mask_paths[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a5d2ff-b6ec-4298-bd61-54445c735f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in tqdm(mask_paths):\n",
    "    mask = np.load(path)\n",
    "    lung_sdf = sdf(mask, organ=1)\n",
    "    lung_sdf = np.expand_dims(lung_sdf, -1)\n",
    "    np.save(path.replace('Masks', 'SDF'), lung_sdf)\n",
    "    #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd689d8-0c76-4924-9fb5-043d824c6687",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_1.11",
   "language": "python",
   "name": "torch_1.11"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
